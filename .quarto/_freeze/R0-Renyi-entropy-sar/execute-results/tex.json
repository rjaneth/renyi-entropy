{
  "hash": "f9ef6cb9e2889a84d04a45ea762d6349",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Quantifying Roughness in SAR Imagery with the Rényi Entropy\nformat:\n  ieee-pdf:\n    pdf-engine: pdflatex # xelatex\n    keep-tex: true  \n    classoption: lettersize\n    tex-author-no-affiliation: true\n    #conference: true # comment this line to use journal\n    #journaltype: conference # comment this line to use journal\n    fig-cap-location: bottom # to crossref figure\n    link-citations: true\n    colorlinks: true\n    linkcolor: black # equations\n    citecolor: black # cites\n    urlcolor: black\n  #ieee-html: default\nauthor:\n  - name: Janeth Alpala\n    email: janeth.alpala@ufpe.br\n    orcid: 0000-0002-0265-6236\n  - name: Abraão D.&nbsp;C.&nbsp;Nascimento\n    affiliations:\n      - name: Universidade Federal de Pernambuco\n        department: Departamento de Estatística\n        city: Recife\n        country: Brazil\n        postal-code: 50670-901\n    email: abraao@de.ufpe.br\n    orcid: 0000-0003-2673-219X\n  - name: Alejandro C.&nbsp;Frery\n    affiliations:\n      - name: Victoria University of Wellington\n        department: School of Mathematics and Statistics\n        city: Wellington\n        country: New Zealand\n        postal-code: 6140\n    orcid: 0000-0002-8002-5341\n    email: alejandro.frery@vuw.ac.nz\n    membership: Fellow, IEEE\n    attributes:\n      corresponding: true\n    note: |\n      Janeth Alpala and Abraão D. C. Nascimento are with the Departamento de Estatística, Universidade Federal de Pernambuco, Recife, 50670-901 PE, Brazil (e-mails: janeth.alpala@ufpe.br, abraao@de.ufpe.br).  \n      \n      Alejandro C. Frery is with the School of Mathematics and Statistics, Victoria University of Wellington, Wellington, 6140, New Zealand (e-mail: alejandro.frery@vuw.ac.nz). \\emph{Corresponding author: Alejandro C. Frery.}\n      \n      Data and code are available at: <https://github.com/rjaneth/renyi-entropy> \n    # bio: |\n    #   Use `IEEEbiographynophoto` and the author name\n    #   as the argument followed by the biography text.\n    # note: \"Template created June 23, 2023; revised March 29, 2025.\"\nabstract: |\n  Quantifying surface roughness in synthetic aperture radar (SAR) data is critical for accurate geophysical interpretation and remote sensing applications. \n  We propose a test statistic based on a non-parametric estimation of Rényi entropy to characterize surface roughness from SAR intensity data. \n  The statistic is refined using bootstrap to improve its stability, size and power. \n  This approach enhances roughness quantification by capturing scale-dependent variations and addressing data-driven uncertainty.\n  Experimental results demonstrate the robustness of the proposed method in distinguishing roughness patterns, offering a statistically rigorous tool for SAR-based terrain analysis.\n  <!-- Synthetic aperture radar (SAR) systems have already been successfully used to solve remote sensing problems.  -->\n  <!-- A disadvantage of SAR images is the presence of speckle, which is fully developed in homogeneous areas and gamma-distributed in these scenes.  -->\n  <!-- In heterogeneous areas, the intensity values are $\\mathcal{G}^0_I$-distributed.  -->\n  <!-- In this way, the identification of roughness SAR areas (as opposed to homogeneous ones) is an important task.  -->\n  <!-- In this work, we propose a family of hypothesis tests driven by an order parameter to identify roughness features in SAR intensity data using Rényi entropy.  -->\n  <!-- In particular, we use a non-parametric estimator for the Rényi entropy and investigate some of its properties.  -->\n  <!-- As a practical evaluation method, we develop $p$-value maps on which one can observe both (i) the heterogeneous evidence change per texture and (ii) the prediction of homogeneous and heterogeneous categories.  -->\n  <!-- The results are in favor of the Rényi-based heterogeneity detector compared to the one based on Shannon entropy. -->\nkeywords: [Rényi entropy, Gamma distribution, heterogeneity, SAR, hypothesis tests, bootstrap]\n \n#funding: \n # statement: \"The `quarto-ieee` \"\npageheader:\n  left: Journal XXX, Month Year\n  right: #'D. Folio:  A Sample Article Using quarto-ieee'\n  \nheader-includes:\n   #- \\usepackage[english]{babel}\n   - \\usepackage{bm,bbm}\n   - \\usepackage{mathrsfs}\n   - \\usepackage{nccmath}\n   - \\usepackage{amssymb}\n   - \\usepackage{mathtools}\n   - \\usepackage{siunitx}\n   - \\usepackage{graphicx}\n   - \\usepackage{url}\n   - \\usepackage[T1]{fontenc}\n   - \\usepackage{booktabs}\n   - \\usepackage{color}\n   - \\usepackage{hyperref}\n   #- \\hypersetup{draft} #Desactiva enlaces y referencias cruzadas\n   - \\usepackage{float}\n   - \\usepackage{array}\n   - \\usepackage{multirow}\n   - \\usepackage{wrapfig}\n   - \\usepackage{colortbl}\n   - \\usepackage{pdflscape}\n   - \\usepackage{xcolor}\n#bibliography: references.bib\nbibliography: ../../Common/references.bib\n\n# execute:\n#   echo: false\n#   eval: true\n\n---\n\n\n\n\n\\renewcommand{\\tablename}{TABLE}\n# Introduction\n[S]{.IEEEPARstart}[ynthetic]{}\n Aperture Radar (SAR) technology has become essential for a wide range of applications&nbsp;[@Yu2023;@Akbarizadeh2012;@Mondini2021]. \n It provides high-resolution data that is independent of sunlight and operates in a variety of weather conditions that facilitate global Earth monitoring&nbsp;[@Zeng2020].\nDespite its advantages, the effective use of SAR data depends on understanding its statistical properties because this data is affected by speckle, a noise-like interference effect&nbsp;[@Argenti2013; @Choi2019; @Baraha2023]. In intensity format, speckle is typically non-Gaussian, and its presence complicates subsequent image analysis tasks.\n\nThe $\\mathcal{G}^0_I$ distribution effectively characterizes SAR intensity data because it captures different levels of roughness. \nA limiting case is the Gamma distribution, which arises when speckle is fully developed, indicating textureless regions. \nAlthough these assumptions offer flexibility in describing SAR intensities, selecting the appropriate distribution can be challenging for two main reasons: the small sample sizes used in practical applications and the inherent difficulties associated with parameter estimation. \nThese challenges complicate model selection and highlight the need to explore alternative statistical approaches.\n\nEntropy measures have gained attention as valuable statistical tools for analyzing SAR data, with applications in edge detection&nbsp;[@Nascimento2014], \nsegmentation&nbsp;[@Nobre2016], \nclassification&nbsp;[@Cassetti2022], \nand noise reduction&nbsp;[@Chan2022].\nTraditionally, Shannon entropy&nbsp;[@Shannon1948] has been widely used to quantify data uncertainty and disorder. \nWe explore a more general information measure: Rényi entropy—a generalization of Shannon’s formulation. \nThis more flexible approach provides additional insights for identifying heterogeneity, making it a promising tool for enhancing SAR image analysis.\n\nWe propose a statistical test based on a non-parametric estimator of Rényi entropy to identify heterogeneous regions in SAR data.\nThe test assesses whether the observed Rényi entropy significantly differs from its expected theoretical value under the assumption of homogeneity.\nCompared to our previous approach using Shannon entropy&nbsp;[@Frery2024], the Rényi-based approach improves the detection of heterogeneity.\n\nThe remainder of this article is organized as follows.\nSection&nbsp;\\ref{sec:pre} overviews the statistical models for SAR intensity data and introduces Rényi entropy.\nSection&nbsp;\\ref{sec:met} describes the proposed hypothesis test and the test statistic.\nSection&nbsp;\\ref{sec:app} evaluates the performance of the test using SAR data.\nFinally, the concluding remarks are drawn in Section&nbsp;\\ref{sec:conclusion}.\n\n# PRELIMINARIES {#sec:pre} \n\n\n## Statistical Models\n\nThe main distributions considered for SAR intensity data are the $\\Gamma_{\\text{SAR}}$ distribution, which is suitable for fully developed speckle, and the $\\mathcal{G}^0_I$ distribution, which is able to describe roughness&nbsp;[@Frery1997]. These distributions are characterized by the following probability density functions (pdfs):\n\\begin{equation}\n\tf_{\\Gamma_{\\text{SAR}}}\\bigl(z;L, \\mu \\bigr) \n    = \\frac{L^L}{\\Gamma(L)\\,\\mu^L} z^{L-1} \n    \\exp \\biggl(-\\frac{Lz}{\\mu}\\biggr)\n    \\mathbbm 1_{\\mathbbm R_+}(z), \\label{E:gamma1}\n\\end{equation}\nand\n\\begin{multline}\n    f_{\\mathcal{G}^0_I}\\bigl(z; \\mu, \\alpha, L \\bigr) \n    = \\frac{L^L\\,\\Gamma(L-\\alpha)}\n    {\\bigl[-\\mu(\\alpha+1)\\bigr]^{\\alpha} \\Gamma(-\\alpha)\\,\\Gamma(L)}\\\\\n    \\frac{z^{L-1}}\n    {\\bigl[-\\mu(\\alpha+1)+Lz\\bigr]^{L-\\alpha}}\n    \\mathbbm 1_{\\mathbbm R_+}(z), \\label{E:gi01}\n\\end{multline}\nwhere $\\mu > 0$ is the mean,\n$\\alpha < 0$ measures the roughness, $L \\geq 1$ is the number of\nlooks, $\\Gamma(\\cdot)$ is the gamma function, and\n$\\mathbbm 1_{A}(z)$ is the indicator function of the set $A$. \nAs demonstrated by&nbsp;[@Frery1997], the $\\Gamma_{\\text{SAR}}$  model is a particular case of the $\\mathcal{G}^0_I$ distribution. Specifically, for a given $\\mu$ fixed,\n$$\nf_{\\mathcal{G}^0_I}\\big(z; \\mu, \\alpha, L\\big)\n\\longrightarrow \nf_{\\Gamma_{\\text{SAR}}}(z;L, \\mu) \n$$\nwhen $\\alpha\\to-\\infty$.\n\n## Rényi Entropy\n\nIntroduced by Alfréd Rényi in 1961&nbsp;[@renyi1961measures], this measure generalizes several well-known entropies, including Shannon's&nbsp;[@Ribeiro2021]. \nFor a continuous random variable $Z$ with pdf $f(z)$, the Rényi entropy of order $\\lambda \\in \\mathbbm R_+ \\setminus \\{1\\}$, is defined as:\n\\begin{equation}\n\\label{E:entropy2}\nH_\\lambda(Z) = \\frac{1}{1 - \\lambda} \\ln \\int_{-\\infty}^{\\infty} [f(z)]^\\lambda \\, dz.\n\\end{equation}\nUsing&nbsp;\\eqref{E:entropy2}, we derive closed-form expressions for the Rényi entropy of the $\\Gamma_{\\mathrm{SAR}}$ and the $\\mathcal{G}^0_I$ distributions:\n\\begin{multline}\n\\label{eq-HGammaSAR}\nH_\\lambda\\bigl(\\Gamma_{\\text{SAR}}(L, \\mu)\\bigr)\n= \n\\ln \\mu - \\ln L + \\frac{1}{1-\\lambda}\n\\Bigl[\n  -\\lambda\\,\\ln\\Gamma(L)  \\\\ + \\ln\\Gamma\\bigl(\\lambda(L-1)+1\\bigr)  - \\bigl(\\lambda(L-1)+1\\bigr)\\,\\ln\\lambda\n\\Bigr],\n\\end{multline}\nand\n\\begin{multline}  \n\\label{eq-HGI0}  \nH_\\lambda\\bigl(\\mathcal{G}^0_I(\\mu, \\alpha, L)\\bigr) = H_\\lambda\\bigl(\\Gamma_{\\text{SAR}}(L, \\mu)\\bigr) + \\ln(-1 - \\alpha) \\\\  \n+ \\frac{1}{1 - \\lambda} \\Bigl[ \\lambda\\bigl(\\ln\\Gamma(L - \\alpha) - \\ln\\Gamma(-\\alpha)\\bigr) \\\\ \n+ \\ln\\Gamma\\bigl(\\lambda(-\\alpha + 1) - 1\\bigr) - \\ln\\Gamma\\bigl(\\lambda(L - \\alpha)\\bigr) \\\\\n+ \\bigl(\\lambda(L-1)+1\\bigr)\\ln\\lambda \\Bigr].  \n\\end{multline}\nThe derivation of the latter result is proven in the Appendix.\nNote that the Rényi entropy of $\\mathcal{G}^0_I$ can be expressed in terms of that of $\\Gamma_{\\mathrm{SAR}}$, with additional terms depending on the roughness parameter $\\alpha$. As $\\alpha \\to -\\infty$, these terms tend to zero, reducing&nbsp;\\eqref{eq-HGI0} to&nbsp;\\eqref{eq-HGammaSAR}.\n\n@fig-plot illustrates this convergence by showing $H_\\lambda(\\mathcal{G}^0_I)$  as a function of $\\mu$ for different values of $\\alpha$. As $\\alpha$ decreases, the curves approach $H_\\lambda(\\Gamma_{\\text{SAR}})$ (solid black line). This confirms that $\\Gamma_{\\text{SAR}}$ is a limiting case of $\\mathcal{G}^0_I$.\n<!-- ACF Have you checked if it is possible to state the difference between \\label{eq-HGI0} and \\label{eq-HGammaSAR}? At the end of the day, that is what we want to assess. -->\n<!-- Corrected -->\n\n\n::: {.cell fig.fullwidth='true'}\n::: {.cell-output-display}\n![$H_{\\lambda}(\\mathcal{G}^0_I)$ converges to the $H_{\\lambda}(\\Gamma_{\\text{SAR}})$ when $\\alpha\\to-\\infty$, with $L=8$ and $\\lambda=0.8$.](R0-Renyi-entropy-sar_files/figure-pdf/fig-plot-1.pdf){#fig-plot fig-pos='hbt' width=45%}\n:::\n:::\n\n\n\n\n## Non-parametric Estimation of Rényi Entropy\n\nIn order to estimate&nbsp;\\eqref{E:entropy2} from a random sample, one may estimate the parameters that index the probability density function $f$, and integrate.\nThis approach heavily relies on the model assumptions and on the absence of outliers.\nAlternatively, one may estimate directly $f$.\nSuch non-parametric estimation of $H(Z)$ has been widely studied using spacing-based estimators, which rely on differences between order statistics&nbsp;[@vasicek1976test;@Bert1992; @Ebrahimi1994; @Wieczorkowski1999; @IbrahimAlOmari2014]. \nRecently, Al-Labadi et al.&nbsp;[@AlLabadi2024] proposed a non-parametric estimator for Rényi entropy following this approach.  \n\nLet $\\bm{Z}=(Z_1, Z_2,\\ldots,Z_n)$ be an independent and identically distributed random sample of size $n$ from a distribution $F$, and let $Z_{(1)} \\leq Z_{(2)} \\leq \\dots \\leq Z_{(n)}$ denote its order statistics.\nThe $m$-spacing density estimator is defined as:\n$$\nf_n(Z_{(i)}) = \\frac{c_i m / n}{Z_{(i+m)} - Z_{(i-m)}},\n$$\nwhere $Z_{(i-m)} = Z_{(1)}$ when $i \\leq m$, and $Z_{(i+m)} = Z_{(n)}$ if $i \\geq n - m$. \nThe coefficient $c_i$ is given by:\n$$\nc_i = \n\\begin{cases}\n\\frac{m + i - 1}{m}, & \\text{if } 1 \\leq i \\leq m, \\\\%[6pt]\n2, & \\text{if } m+1 \\leq i \\leq n - m, \\\\%[6pt]\n\\frac{n + m - i}{m}, & \\text{if } n - m + 1 \\leq i \\leq n.\n\\end{cases}\n$$\n\nFollowing Vasicek&nbsp;[@vasicek1976test] and Ebrahimi et al.&nbsp;[@Ebrahimi1994] for Shannon entropy estimation, and using the $m$-spacing density estimator, the Rényi entropy can be estimated as:\n\\begin{align}\n\\label{eq:est_R}\n\\widehat{H}_\\lambda(\\bm{Z}) = \\frac{1}{1 - \\lambda} \\ln \\left[\\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{c_i m / n}{Z_{(i+m)} - Z_{(i-m)}} \\right)^{\\lambda - 1} \\right].\n\\end{align}\nThis estimator is asymptotically consistent, i.e., it converges in\nprobability to the true value when $m,n\\rightarrow\\infty$ and\n$m/n\\rightarrow0$. \nWe used the heuristic spacing $m=\\left[\\sqrt{n}+0.5\\right]$.\n\n# PROPOSED METHODOLOGY {#sec:met}\n\n## On $\\lambda$ optimality for a sample size\n\nWe aim to determine the optimal order $\\lambda$ for the Rényi entropy estimator for a sample size $n=49$.\nTo identify this optimal value, we analyze both the mean squared error (MSE) and bias of the estimator across different values of $\\lambda$. Lower MSE and bias indicate better performance of the estimator in approximating the true entropy.  \n\nWe found that for $L > 1$ the optimal value is $\\lambda = 0.9$, as it minimizes the MSE while maintaining a low bias.\nHowever, for $L = 1$, the optimal $\\lambda$ tends to be higher and we chose $\\lambda = 3$ to achieve good results. \n@fig-plotf illustrates the case for $L = 5$.\n\n\n::: {.cell fig.fullwidth='true'}\n::: {.cell-output-display}\n![Bias and MSE as a function of $\\lambda$, with $n=49$, $L=5$.](R0-Renyi-entropy-sar_files/figure-pdf/fig-plotf-1.pdf){#fig-plotf fig-pos='hbt' width=42%}\n:::\n:::\n\n\n\n## Bootstrap Correction for Entropy Estimator\n\nFollowing Refs.&nbsp;[@Frery2024;@Alpala2024], we refined the non-parametric entropy estimator $\\widehat{H}_{\\lambda}$ in&nbsp;\\eqref{eq:est_R} reducing its bias with bootstrap, obtaining $\\widetilde{H}_{\\lambda}$:\n$$\n\\widetilde{H}_{\\lambda} = 2\\widehat{H}_{\\lambda}(\\bm{Z}) - \\frac{1}{B} \\sum_{b=1}^{B} \\widehat{H}_{\\lambda}(\\bm{Z}^{(b)}),\n$$\nwhere $B$ is the number of bootstrap replications, and $\\bm{Z}^{(b)}$ is the $b$-th resampled dataset obtained by drawing $n$ observations with replacement from $\\bm{Z}$.\n  \nA Monte Carlo study with $1000$ replications for each sample size $n \\in \\{9, 25, 49, 81, 121\\}$ from the $\\Gamma_{\\text{SAR}}$ ($\\mu=1, L=5$) confirms that for $\\lambda=0.9$, the bootstrap-corrected estimator $\\widetilde{H}_{\\lambda}$ ($B=200$) reduces both bias and MSE compared to the original $\\widehat{H}_{\\lambda}$, with significant improvements for small sample sizes, as shown in&nbsp;@fig-Plot_bias_msef3.\n\n<!-- ACF Remove the minor vertical grid (there is nothing between 49 and 81) -->\n<!-- Corrected -->\n\n\n::: {.cell}\n\n:::\n\n::: {.cell fig.fullwidth='true'}\n::: {.cell-output-display}\n![Bias and MSE of the Rényi entropy estimators for $\\Gamma_{\\text{SAR}}$.](R0-Renyi-entropy-sar_files/figure-pdf/fig-Plot_bias_msef3-1.pdf){#fig-Plot_bias_msef3 fig-pos='hbt' width=42%}\n:::\n:::\n\n\nFor subsequent simulations we use the $\\widetilde{H}_{\\lambda}$ estimator.\n\n\n\n## Hypothesis Testing \n\nWe test whether the observed data come from a homogeneous ($\\Gamma_{\\text{SAR}}$) or a heterogeneous ($\\mathcal{G}^0_I$) region, as follows:\n\\begin{equation}\\label{eq:hypothesis_test}\n\\begin{cases}\n\\mathcal{H}_0: \\mathbb{E}[\\widetilde{H}_{\\lambda}] = H_{\\lambda}(\\Gamma_{\\text{SAR}}) & \\text{(Homogeneous region)}, \\\\[6pt]\n\\mathcal{H}_1: \\mathbb{E}[\\widetilde{H}_{\\lambda}] = H_{\\lambda}(\\mathcal{G}^0_I) & \\text{(Heterogeneous region)}.\n\\end{cases}\n\\end{equation}\n  \nUnder $\\mathcal{H}_0$, the expected value of the entropy estimator should match the theoretical $H_{\\lambda}(\\Gamma_{\\text{SAR}})$. \nIf the estimated entropy significantly deviates from its expected value, we reject $\\mathcal{H}_0$, indicating the presence of heterogeneity.\n\nSince homogeneity corresponds to $\\alpha \\to -\\infty$ in the $\\mathcal{G}^0_I$ model, classical inference methods are inapplicable. \nInstead, we propose a test statistic based on the Rényi entropy estimator, comparing it with its theoretical expectation under $\\mathcal{H}_0$ to distinguish between homogeneous and heterogeneous areas.\n\n\n## The Proposed Test\n\nAssume we have an estimator $\\widetilde{H}_{\\lambda}$ for the Rényi entropy of an arbitrary model. For testing&nbsp;\\eqref{eq:hypothesis_test}, this estimator is expected to be close to the theoretical expression given in Equation&nbsp;\\eqref{eq-HGammaSAR}. \nSince $L\\geq1$ is known, we define the test statistic as follows:\n\\begin{multline}\n\\label{eq-test}\nS_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L) = \\widetilde{H}_{\\lambda} - \\bigl\\{\\ln \\widehat{\\mu} - \\ln L + \\frac{1}{1-\\lambda}\n\\bigl[-\\lambda\\,\\ln\\Gamma(L) \\\\ \n+ \\ln\\Gamma\\bigl(\\lambda(L-1)+1\\bigr)  \n- \\bigl(\\lambda(L-1)+1\\bigr)\\,\\ln\\lambda\n\\bigr]\\bigr\\},\n\\end{multline}\nwhere $\\widehat{\\mu}={n}^{-1}\\sum_{i=1}^n Z_{i}$ is the sample mean.\nWhen the null hypothesis holds, this test statistic is expected to be close to zero.\n@fig-density_entropyR shows the empirical density of $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$, based on $10^4$ replications of the $\\Gamma_{\\text{SAR}}$ model for each sample size $n \\in \\{49,81, 121\\}$ with $\\lambda=0.9$ and $L \\in \\{5,18\\}$.\n<!-- ACF 10^4 replications of samples of size?   -->\n<!-- Corrected -->\n\n\n::: {.cell}\n\n:::\n\n::: {.cell fig.fullwidth='true'}\n::: {.cell-output-display}\n![Empirical densities of $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$ under $\\mathcal{H}_0$.](R0-Renyi-entropy-sar_files/figure-pdf/fig-density_entropyR-1.pdf){#fig-density_entropyR fig-pos='hbt' width=47%}\n:::\n:::\n\n\n\nVasicek&nbsp;[@vasicek1976test] proved that, for sufficiently large samples, $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$ asymptotically follows a normal distribution:\n\\begin{equation*}\nS_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L) \\overset{d}{\\longrightarrow} \\mathcal{N}(\\mu_S,\\,\\sigma^{2}_S)\\,,\n\\end{equation*}\nwhere $d$ represents convergence in distribution. Here, $\\mu_S  = \\mathbb{E}[S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)]$ and $\\sigma^{2}_S = \\text{Var}[S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)]$ are the theoretical mean and variance of $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$.\n\nWe define the standardized test statistic:\n\\begin{equation*}\n\\varepsilon = \\frac{S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L) - \\hat{\\mu}_S}{\\hat{\\sigma}_S},\n\\end{equation*}\nwhere $\\hat{\\mu}_S$ and $\\hat{\\sigma}_S$ are the empirical mean and standard deviation of $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$, obtained by Monte Carlo simulations under the null hypothesis. \nBy the central limit theorem, $\\varepsilon$ asymptotically follows a standard normal distribution:\n\\begin{equation*}\n\\varepsilon \\overset{d}{\\longrightarrow} \\mathcal{N}(0,1)\\,.\n\\end{equation*}\nThus, the $p$-values are calculated as $2\\Phi(-|\\varepsilon|)$,\nwhere $\\Phi(\\cdot)$ is the cumulative distribution function of the standard normal distribution.\n@fig-density_entropyR_standardized0 shows smoothed histograms of standardized test statistics.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell fig.fullwidth='true'}\n::: {.cell-output-display}\n![Standardized empirical densities of $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$ under $\\mathcal{H}_0$.](R0-Renyi-entropy-sar_files/figure-pdf/fig-density_entropyR_standardized0-1.pdf){#fig-density_entropyR_standardized0 fig-pos='hbt' width=35%}\n:::\n:::\n\n\nIn general, hypotheses tests aim to control the Type&nbsp;I error rate (size) with high test power (sensitivity to departures from $\\mathcal{H}_0$, low Type&nbsp;II error rate).\nTo assess these properties, we performed a Monte Carlo simulation with $1000$ replications at significance levels \\SI{1}{\\percent}, \\SI{5}{\\percent}, and \\SI{10}{\\percent}, evaluating the test under the null hypothesis ($\\Gamma_{\\text{SAR}}$ distribution), varying sample size and values of $L$ for $\\mu=1$. \n<!-- ACF I wish you had used the siunitx package for typing percentages, but not if this is incompatible with the tables -->\n<!-- Corrected -->\nThe observed Type&nbsp;I error rates align with the nominal values, confirming the test validity.\n\nFurther, we examined the power under the alternative hypothesis ($\\mathcal{G}^0_I$ distribution) with $\\mu=1$, $\\lambda=0.9$ and $\\alpha=-2$.\nAs expected, power improves as the sample size and number of looks increase, demonstrating the test effectiveness. The results are shown in Table&nbsp;\\ref{tab:table_size_power}.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\\begin{table}[htb]\n\\centering\\centering\n\\caption{\\label{tab:table_size_power}Size and Power of the $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z})$ test statistic.}\n\\resizebox{\\ifdim\\width>\\linewidth\\linewidth\\else\\width\\fi}{!}{\n\\fontsize{7}{9}\\selectfont\n\\begin{tabu} to \\linewidth {>{\\centering}X>{\\centering}X>{\\centering}X>{\\centering}X>{\\centering}X>{\\centering}X>{\\centering}X>{\\centering}X}\n\\toprule\n\\multicolumn{2}{c}{ } & \\multicolumn{3}{c}{Size} & \\multicolumn{3}{c}{Power} \\\\\n\\cmidrule(l{3pt}r{3pt}){3-5} \\cmidrule(l{3pt}r{3pt}){6-8}\n\\multicolumn{1}{c}{$\\bm{L}$} & \\multicolumn{1}{c}{$\\bm{n}$} & \\multicolumn{1}{c}{$\\hphantom{00}\\SI{1}{\\percent}$} & \\multicolumn{1}{c}{$\\hphantom{00}\\SI{5}{\\percent}$} & \\multicolumn{1}{c}{$\\hphantom{00}\\SI{10}{\\percent}$} & \\multicolumn{1}{c}{$\\hphantom{00}\\SI{1}{\\percent}$} & \\multicolumn{1}{c}{$\\hphantom{00}\\SI{5}{\\percent}$} & \\multicolumn{1}{c}{$\\hphantom{00}\\SI{10}{\\percent}$}\\\\\n\\midrule\n & 25 & $\\phantom{-}0.014$ & $\\phantom{-}0.050$ & $\\phantom{-}0.100$ & $\\phantom{-}0.978$ & $\\phantom{-}0.994$ & $\\phantom{-}0.993$\\\\\n\n & 49 & $\\phantom{-}0.011$ & $\\phantom{-}0.048$ & $\\phantom{-}0.109$ & $\\phantom{-}0.994$ & $\\phantom{-}1.000$ & $\\phantom{-}0.999$\\\\\n\n & 81 & $\\phantom{-}0.012$ & $\\phantom{-}0.057$ & $\\phantom{-}0.103$ & $\\phantom{-}0.998$ & $\\phantom{-}0.998$ & $\\phantom{-}0.999$\\\\\n\n\\multirow{-4}{*}[\\normalbaselineskip]{\\centering\\arraybackslash 5} & 121 & $\\phantom{-}0.013$ & $\\phantom{-}0.061$ & $\\phantom{-}0.116$ & $\\phantom{-}0.999$ & $\\phantom{-}0.999$ & $\\phantom{-}0.997$\\\\\n\\cmidrule{1-8}\n & 25 & $\\phantom{-}0.010$ & $\\phantom{-}0.051$ & $\\phantom{-}0.105$ & $\\phantom{-}0.996$ & $\\phantom{-}0.999$ & $\\phantom{-}1.000$\\\\\n\n & 49 & $\\phantom{-}0.008$ & $\\phantom{-}0.056$ & $\\phantom{-}0.109$ & $\\phantom{-}1.000$ & $\\phantom{-}0.999$ & $\\phantom{-}1.000$\\\\\n\n & 81 & $\\phantom{-}0.012$ & $\\phantom{-}0.052$ & $\\phantom{-}0.097$ & $\\phantom{-}0.999$ & $\\phantom{-}0.999$ & $\\phantom{-}0.999$\\\\\n\n\\multirow{-4}{*}[\\normalbaselineskip]{\\centering\\arraybackslash 8} & 121 & $\\phantom{-}0.016$ & $\\phantom{-}0.070$ & $\\phantom{-}0.116$ & $\\phantom{-}0.998$ & $\\phantom{-}1.000$ & $\\phantom{-}0.999$\\\\\n\\cmidrule{1-8}\n & 25 & $\\phantom{-}0.016$ & $\\phantom{-}0.051$ & $\\phantom{-}0.111$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$\\\\\n\n & 49 & $\\phantom{-}0.014$ & $\\phantom{-}0.047$ & $\\phantom{-}0.098$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$\\\\\n\n & 81 & $\\phantom{-}0.013$ & $\\phantom{-}0.048$ & $\\phantom{-}0.106$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$\\\\\n\n\\multirow{-4}{*}[\\normalbaselineskip]{\\centering\\arraybackslash 18} & 121 & $\\phantom{-}0.012$ & $\\phantom{-}0.066$ & $\\phantom{-}0.110$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$ & $\\phantom{-}1.000$\\\\\n\\bottomrule\n\\end{tabu}}\n\\end{table}\n\n\n\n# Applications to SAR Data {#sec:app}\nIn this section, we compare two test statistics for detecting heterogeneity in SAR data: (i) the Rényi entropy-based test, $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$, described in&nbsp;\\eqref{eq-test}; and (ii) the Shannon entropy-based test, $S_{\\widetilde{H}_{\\text{AO}}}(\\bm{Z}; L)$, which is based on the Al-Omari estimator proposed in&nbsp;[@IbrahimAlOmari2014] and was improved via bootstrap in our previous work. The details of this test can be found in Frery et al.&nbsp;[@Frery2024].\n<!-- ACF What is $S_{\\widetilde{H}_{\\text{AO}}}(\\bm{Z}; L)$? -->\n<!-- JA: I added a brief explanation, indicating that it is based on the Al-Omari estimator and was improved with bootstrap. -->\n\nWe applied these tests to images covering urban, agricultural, and water regions. \nWe analyzed images from London, United Kingdom;  the surroundings of Munich, Germany; and  Dublin Port, Ireland, as shown in Figs.&nbsp;\\ref{fig:london-a},&nbsp;\\ref{fig:munich-a}, and&nbsp;\\ref{fig:dublin-a}. All images were acquired in HH polarization.\nTable&nbsp;\\ref{tab:table_param} provides the detailed acquisition parameters of these images.\n<!-- ACF They all have HH polarization; the column is not informative, and can be deleted to gain space -->\n<!-- Corrected -->\n\\renewcommand{\\arraystretch}{3}   \n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}[hbt]\n\\centering\\centering\n\\caption{\\label{tab:table_param}Parameters of selected SAR images.}\n\\centering\n\\resizebox{\\ifdim\\width>\\linewidth\\linewidth\\else\\width\\fi}{!}{\n\\fontsize{21}{23}\\selectfont\n\\begin{tabu} to \\linewidth {>{\\centering\\arraybackslash}p{3.0cm}>{\\centering\\arraybackslash}p{3.7cm}>{\\centering\\arraybackslash}p{1.5cm}>{\\centering\\arraybackslash}p{4cm}>{\\centering\\arraybackslash}p{1.5cm}>{\\centering\\arraybackslash}p{4.0cm}>{\\centering\\arraybackslash}p{4.5cm}}\n\\toprule\n\\multicolumn{1}{c}{\\textbf{Site}} & \\multicolumn{1}{c}{\\textbf{Mission}} & \\multicolumn{1}{c}{\\textbf{Band}} & \\multicolumn{1}{c}{\\textbf{Size (pixels)}} & \\multicolumn{1}{c}{$\\bm{L}$} & \\multicolumn{1}{c}{\\textbf{Resolution [m]}} & \\multicolumn{1}{c}{\\textbf{Acquisition Date}}\\\\\n\\midrule\nLondon & TanDEM-X & X & $2000\\times2000$ & $1$ & $0.99/0.99$ & 12-11-2021\\\\\nMunich & UAVSAR & L & $1024\\times1024$ & $12$ & $4.9/7.2$ & 16-04-2015\\\\\nDublin & TanDEM-X & X & $1100\\times1100$ & $16$ & $1.35/1.35$ & 03-09-2017\\\\\n\\bottomrule\n\\end{tabu}}\n\\end{table}\n\n\n:::\n:::\n\n\nWe used sliding windows of size $7\\times 7$.\nThe results are presented as $p$-value maps and binary maps at a $0.05$ significance level. \nFigs.&nbsp;\\ref{fig:london-b}--\\ref{fig:london-c},&nbsp;\\ref{fig:munich-b}--\\ref{fig:munich-c}, and&nbsp;\\ref{fig:dublin-b}--\\ref{fig:dublin-c} correspond to $S_{\\widetilde{H}_{\\lambda}}(\\bm{Z}; L)$, while Figs.&nbsp;\\ref{fig:london-d}--\\ref{fig:london-e},&nbsp;\\ref{fig:munich-d}--\\ref{fig:munich-e}, and&nbsp;\\ref{fig:dublin-d}--\\ref{fig:dublin-e} correspond to $S_{\\widetilde{H}_{\\text{AO}}}(\\bm{Z}; L)$.\n\nThe $p$-value maps use a color gradient, where darker regions indicate areas with higher roughness and lighter regions denote smoother, less textured surfaces.\nThe binary maps classify these results: white areas represent $p$-values greater than $0.05$, indicating no statistical evidence to reject the null hypothesis (homogeneous regions). \nIn contrast, black areas represent regions with $p$-values below $0.05$, providing statistical evidence to reject the null hypothesis and indicating heterogeneity.\n\nThe Rényi entropy-based test demonstrated greater sensitivity in detecting textural variations compared to the Shannon-based test, due to the flexibility provided by the parameter $\\lambda$, as observed in the binary maps in Figs.&nbsp;\\ref{fig:london-c},&nbsp;\\ref{fig:munich-c}, and&nbsp;\\ref{fig:dublin-c}.\n<!-- ACF Where is the Shannon-based approach shown? -->\n<!-- JA: The results of the Shannon-based approach can be observed in the corresponding binary maps. -->\n\n\n```{=latex}\n\\begin{figure*}[hbt]\n    \\centering\n    \\begin{subfigure}{0.17\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/london_2000.png}\n        \\caption{ SAR image}\n        \\label{fig:london-a}\n    \\end{subfigure}\n    \\begin{subfigure}{0.22\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_pvalue_london_renyi.png}\n        \\caption{$p$-value map for $\\small{S_{\\widetilde{H}_{\\lambda}}}$}\n        \\label{fig:london-b}\n    \\end{subfigure}\n    \\begin{subfigure}{0.17\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_005_london_renyi_L1_.png}\n        \\caption{Binary map for $\\small{S_{\\widetilde{H}_{\\lambda}}}$}\n        \\label{fig:london-c}\n    \\end{subfigure}\n    \\begin{subfigure}{0.22\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_pvalue_london_Shannon_c1.png}\n        \\caption{$p$-value map for $\\tiny{S_{\\widetilde{H}_{\\text{AO}}}}$ }\n        \\label{fig:london-d}\n    \\end{subfigure}\n    \\begin{subfigure}{0.17\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_005_london_shannon.png}\n        \\caption{Binary map for $\\small{S_{\\widetilde{H}_{\\text{AO}}}}$}\n        \\label{fig:london-e}\n    \\end{subfigure}\n    \\caption{Detection of heterogeneous areas in a SAR image over London, UK: comparison with the tests $\\small{S_{\\widetilde{H}_{\\lambda}}}$ and $\\small{S_{\\widetilde{H}_{\\text{AO}}}}$.  }\n    \\label{fig:london}\n\\end{figure*}\n\n```\n\n```{=latex}\n\\begin{figure*}[hbt]\n    \\centering\n    \\begin{subfigure}{0.17\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/munich_1024_2.png}\n        \\caption{SAR image}\n        \\label{fig:munich-a}\n    \\end{subfigure}\n    \\begin{subfigure}{0.23\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_pvalue_muni_renyi.png}\n        \\caption{$p$-value map for $\\small{S_{\\widetilde{H}_{\\lambda}}}$}\n        \\label{fig:munich-b}\n    \\end{subfigure}\n    \\begin{subfigure}{0.16\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_005_munich_renyi.png}\n        \\caption{Binary map for $\\small{S_{\\widetilde{H}_{\\lambda}}}$}\n        \\label{fig:munich-c}\n    \\end{subfigure}\n    \\begin{subfigure}{0.23\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_pvalue_muni_Shan22.png}\n        \\caption{$p$-value map for $S_{\\widetilde{H}_{\\text{AO}}}$}\n        \\label{fig:munich-d}\n    \\end{subfigure}\n    \\begin{subfigure}{0.16\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_005_munich_sh_AO_L12.png}\n        \\caption{Binary map for $\\small{S_{\\widetilde{H}_{\\text{AO}}}}$}\n        \\label{fig:munich-e}\n    \\end{subfigure}\n    \\caption{Detection of heterogeneous areas in a SAR image over Munich, Germany: comparison with the tests $\\small{S_{\\widetilde{H}_{\\lambda}}}$ and $\\small{S_{\\widetilde{H}_{\\text{AO}}}}$.}\n    \\label{fig:munich}\n\\end{figure*}\n\n```\n\n```{=latex}\n\\begin{figure*}[hbt]\n    \\centering\n    \\begin{subfigure}{0.16\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/dublin_1100_hh.png}\n        \\caption{SAR image}\n        \\label{fig:dublin-a}\n    \\end{subfigure}\n    \\begin{subfigure}{0.22\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/dublin_renyi_09_w7_b100.png}\n        \\caption{$p$-value map for $\\small{S_{\\widetilde{H}_{\\lambda}}}$}\n        \\label{fig:dublin-b}\n    \\end{subfigure}\n    \\begin{subfigure}{0.16\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_005_dublin_renyi_09_w7_b100.png}\n        \\caption{Binary map for $\\small{S_{\\widetilde{H}_{\\lambda}}}$}\n        \\label{fig:dublin-c}\n    \\end{subfigure}\n    \\begin{subfigure}{0.22\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/AO_w7_L16_b100.png}\n        \\caption{$p$-value map for $S_{\\widetilde{H}_{\\text{AO}}}$}\n        \\label{fig:dublin-d}\n    \\end{subfigure}\n    \\begin{subfigure}{0.16\\textwidth}\n        \\includegraphics[width=\\linewidth]{./Figures/H_005_AO_w7_L16_b100.png}\n        \\caption{Binary map for $\\small{S_{\\widetilde{H}_{\\text{AO}}}}$}\n        \\label{fig:dublin-e}\n    \\end{subfigure}\n   \\caption{Detection of heterogeneous areas in a SAR image over Dublin Port, Ireland: comparison with the tests $\\small{S_{\\widetilde{H}_{\\lambda}}}$ and $\\small{S_{\\widetilde{H}_{\\text{AO}}}}$.}\n\n    \\label{fig:dublin}\n\\end{figure*}\n\n```\n\n\n\n\n\n# Conclusions {#sec:conclusion}\n\nThis study presented a new statistical approach based on Rényi entropy for detecting heterogeneity in SAR images, distinguishing between fully developed speckle and heterogeneous clutter. \nThe statistics of the proposed test was computed non-parametrically and its performance was evaluated by a Monte Carlo study. \nThe results showed that the method effectively controls the probability of Type&nbsp;I error while maintaining a high detection performance that improves as the sample size increases.\n\n<!-- ACF Again, where are the Shannon results? -->\n<!-- JA: The Shannon results are visually represented through p-value and binary maps for each image -->\nThe effectiveness of the Rényi entropy-based test in SAR images was compared with the Shannon entropy-based test using $p$-value and binary maps. \nThe differences between the two methods are evident in the binary maps at a $0.05$ significance level.\nAlthough both tests successfully detected heterogeneous regions, the Rényi-based test performed better due to its flexibility in adjusting the $\\lambda$ parameter, which allowed for finer differentiation of texture variations.\n\nFuture work will explore additional statistical metrics to improve the comparison between both tests and better quantify their differences in detecting heterogeneity.\n\n\n[]{.appendix options=\"Derivation of the Rényi Entropy of $\\mathcal{G}^0_I$\"}\n\nLet $Z \\sim \\mathcal{G}^0_I(\\alpha, \\gamma, L)$ as defined in Ref.&nbsp;[@Frery2024].\nWe compute $I = \\int_0^\\infty [f_{\\mathcal{G}^0_I}(z)]^\\lambda dz$ using the pdf  \n\\begin{equation*}\nf_{\\mathcal{G}^0_I}(z) = C \\frac{z^{L-1}}{(\\gamma + Lz)^{L-\\alpha}},  \n\\quad C = \\frac{L^L \\Gamma(L - \\alpha)}{\\gamma^\\alpha \\Gamma(-\\alpha) \\Gamma(L)}. \\label{eq:pdf_G0I}\n\\end{equation*}\nSetting $t = Lz/\\gamma$, we obtain  \n\\begin{equation*}\nI = C^\\lambda \\frac{\\gamma^{1-\\lambda+\\lambda\\alpha}}{L^{\\lambda L + 1 - \\lambda}}  \n\\int_0^\\infty \\frac{t^{\\lambda(L-1)}}{(1+t)^{\\lambda(L-\\alpha)}} dt.\n\\end{equation*}\nApplying the Beta function identity, $B(a,b) = \\int_0^\\infty \\frac{t^{a-1}}{(1+t)^{a+b}} dt$ with $a = \\lambda(L-1) + 1$, $b = \\lambda(-\\alpha+1) - 1$, we get  \n\\begin{equation*}\nI= \\gamma^{\\,1 - \\lambda}\\,\n   L^{\\,\\lambda - 1}\n   \\Bigl(\\tfrac{\\Gamma(L - \\alpha)}{\\Gamma(-\\alpha)\\,\\Gamma(L)}\\Bigr)^\\lambda\n   \\,B(a,b).\n\\end{equation*}\nUsing the Rényi entropy definition in \\eqref{E:entropy2}: $H_\\lambda(Z) = (1-\\lambda)^{-1} \\ln I$,\nand substituting $\\gamma = -\\mu(\\alpha + 1)$, we obtain the final expression for $\\mathcal{G}^0_I(\\mu, \\alpha, L)$ in \\eqref{eq-HGI0}.\n\n<!-- # Acknowledgment {-} -->\n\n<!-- This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) - Finance Code 001, and the Fundação de Amparo à Ciência e Tecnologia de Pernambuco (FACEPE), Brazil. -->\n\n# Computational Information {-}\nThis article was written in Quarto and is fully reproducible. We used RStudio version 2024.12.1+563, and R version 4.4.2.\n\n::: {.content-visible when-format=\"pdf\"}\n# References {-}\n:::\n\n\n\n\n<!-- [^issues-1023]: [\"_[longtable not compatible with 2-column LaTeX documents](https://github.com/jgm/pandoc/issues/1023>)_\",  -->\n\n<!-- [^issues-2275]: See the issue here <https://github.com/quarto-dev/quarto-cli/issues/2275> -->\n\n<!-- [IEEEXplore<sup>®</sup>]: <https://ieeexplore.ieee.org/> -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}